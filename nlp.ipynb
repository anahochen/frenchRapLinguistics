{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# On crée un texte composé de plusieurs phrases\n",
    "text_fr = \"Bonjour, Concernant le point de livraison DOMAINE LA COURONNE ALBA LA ROMAINE 07400 ENEDIS / 30001970124818 Je n'ai que les factures de juillet et aout, les autres sont mentionnées fichiers introuvables. Pouvez apporter une solution à ce problème. Cdt. B.BLACHIER\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, Concernant le point de livraison DOMAINE LA COURONNE\n",
      "ALBA\n",
      "LA ROMAINE 07400\n",
      "ENEDIS / 30001970124818\n",
      "Je n'ai que les factures de juillet et aout, les autres sont mentionnées fichiers introuvables.\n",
      "Pouvez apporter une solution à ce problème.\n",
      "Cdt.\n",
      "B.BLACHIER\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr')\n",
    "\n",
    "# On passe le texte par le pipeline\n",
    "doc_fr = nlp(text_fr)\n",
    "\n",
    "# On affiche les phrases\n",
    "for sent in doc_fr.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toi-même', 'ça', 'le', 'debout', 'relativement', 'rare', 'aurait', 'allo', 'extenso', \"t'\", 'desquelles', 'suis', 'troisième', 'pan', 'devers', 'dix-neuf', 'soi', 'mille', 'ô', 'beaucoup', 'n’', 'cher', 'comparable', 'dont', 'ouias', 'miens', 'excepté', 'quoi', 'autre', 'peut', 'ceux', 'même', 'hi', 'douzième', 'possessifs', 'bien', 'suivante', 'vous-mêmes', \"d'\", 'quatre-vingt', 'sinon', 'celui-ci', 'douze', 'celles', 'té', 'd’', 'clac', 'las', 'plutôt', 'suivant', 'meme', 'lesquels', 'uniques', 'devant', 'ollé', 'nous-mêmes', 'moyennant', 'diverse', 'je', 'sauf', 'ces', 'désormais', 'dixième', \"j'\", 'desormais', 'pu', 'tien', 'deuxièmement', 'tes', 'lors', 'comparables', 'miennes', 'pfft', 'soit', 'specifique', 'ès', 'environ', 'malgre', 'sait', 'sous', 'ne', 'certaines', 'différents', 'suivre', 'sapristi', 'suivants', 'chères', 'ouverts', 'fais', 'trop', 'voici', 'huitième', 'hum', 'mienne', 'pure', 'hélas', 'rares', 'differentes', 'maintenant', 'ma', 'tend', 'necessairement', 'la', 'dire', 'auquel', 'sur', 'longtemps', 'avaient', 'celle-là', 'sept', 'une', 'olé', 'notre', 'naturelles', 'parfois', 'prealable', 'effet', 'souvent', 'toi', 'eu', 'vais', 'celui', 'fait', 'anterieur', 'cet', 'du', 'seul', 'zut', 'particulier', 'outre', 'ouverte', 'étais', 'elles-mêmes', 'des', 'te', 'doit', 'cela', 'ouste', 'voilà', 'sien', 'ton', 'étaient', 'ci', 'les', 'rend', 'lès', 'envers', 'toc', 'tant', 'restrictif', 'faisaient', 'vont', 'votre', 'egale', 'aura', 'naturelle', 'dite', 'suffisant', 'son', 'revoilà', 'seule', 'ses', 'si', 'depuis', 'relative', 'floc', 'reste', 'allaient', 'tenant', 'divers', 'puisque', 'neanmoins', 'deuxième', 'celui-là', 'bigre', 'tienne', 'en', 'pfut', 'etc', 'crac', 'pourquoi', 'vous', 'chez', 'eux', 'holà', 'certaine', 'dit', 'néanmoins', 'hors', 'tenir', 't’', 'ceci', 'celles-ci', 'vif', 'parler', 'vingt', 'tsouin', 'auxquelles', 'seize', 'sont', 'â', 'avait', 'ho', 'aujourd', 'aux', 'elles', 'tellement', 'afin', 'vives', 'lequel', 'près', 'diverses', 'dix-sept', 'possessif', 'être', 'font', 'nos', 'ouf', 'attendu', 'procedant', 'quant', 'oust', 'ai', 'allô', 'quatrièmement', 'ouvert', 'comment', 'via', 'tout', 'première', 'unique', 'quatrième', 'maint', 'derriere', 'encore', 'possibles', 'bat', 'pouvait', 'quelle', 'mais', 'leur', 'a', 'nombreuses', 'semblent', 'ainsi', 'lui-même', 'seulement', 'devra', 'semble', 'vas', 'quinze', 'soixante', 'lui', 'peu', 'autrefois', 'i', 'unes', 'onzième', 'sein', 'suit', 'subtiles', 'quiconque', 'à', 'peux', 'certains', 'probable', 'de', 'laisser', 'cependant', 'tac', 'oh', 'chacun', 'proche', 'quatorze', 'exterieur', 'dehors', 'speculatif', 'quelconque', 'sa', 'dix-huit', 'telle', 'pouah', \"qu'\", 'chut', 'doivent', 'personne', 'sienne', 'tente', 'aussi', 'plein', 'quanta', 'moi-même', 'vé', 'très', 'anterieures', 'necessaire', 'et', 'hein', 'toujours', 'parlent', 'sera', 'au', 'duquel', 'alors', 'hormis', 'compris', 'mien', 'dernier', 'lorsque', 'ceux-ci', 'directement', 'nôtre', 'parmi', 'allons', 'enfin', 'bravo', 'tiens', \"quelqu'un\", 'que', 'maximale', 'mes', 'vers', 'neuvième', 'onze', 'etant', 'laquelle', 'hem', 'mon', 'eh', 'selon', 'tiennes', 'jusqu', 'ceux-là', 'été', 'couic', 'aucun', 'différente', 'importe', 'certain', 'cette', 'notamment', 'cinquième', 'j’', 'telles', 'moi-meme', 'ont', 'beau', 'mince', 'hurrah', 'celle', 'cinquantième', 'm’', 'quarante', 'sans', 'sent', 'tic', 'trente', 'strictement', 'precisement', 'vlan', 'jusque', 'etait', \"l'\", 'aie', 'chaque', 'ou', 'premier', 'merci', 'un', 'combien', 'specifiques', 'vifs', 'probante', 'autrement', 'septième', 'pense', 'cinquante', \"c'\", 'passé', 'stop', 'siennes', 'pourrait', 'concernant', 'parce', 'suffisante', 'aupres', 'tel', 'apres', 'tsoin', 'surtout', 'auraient', 'ailleurs', 'avais', 'dedans', 'houp', 'superpose', \"m'\", 'nombreux', 'serait', 'me', 'cinq', 'hop', 'non', 'se', 'qui', 'peuvent', 'exactement', 'est', 'clic', 'trois', 'differents', 'certes', 'tres', 'revoici', 'autrui', 'chère', 'auxquels', 'gens', 'quoique', 'contre', 'deja', 'as', 'avoir', 'après', 'lui-meme', 'abord', 'premièrement', 'seront', 'différent', 'suivantes', 'vôtre', 'hé', 'restant', 'pur', 'pres', 'quelles', 'malgré', 'six', 'o', 'nous', 'memes', 'pire', 'façon', 'rarement', 'quant-à-soi', 'comme', 'vôtres', 'delà', 'parle', \"s'\", 'bas', 'durant', 'minimale', 'nul', 'anterieure', 'etre', 'ha', 'sacrebleu', 'toutes', 'car', 'hui', 'retour', 'semblable', 'différentes', 'dix', 'pourrais', 'elle', 'ayant', 'auront', 'celle-ci', 'tels', 'seraient', 'autres', 'ait', 'mêmes', 'chers', 'était', 'vivat', 'etais', 'rien', 'brrr', 'moindres', 'egales', 'avant', 'fi', 'pif', 'lesquelles', 'l’', 'on', \"n'\", 'egalement', 'pendant', 'euh', 'derniere', 'par', 'dits', 'flac', 'moins', 'plusieurs', 'ce', 'avons', 'il', 'rendre', \"aujourd'hui\", 'c’', 'siens', 'derrière', 'quels', 'dessus', 'quel', 'pas', 'étant', 'sixième', 'assez', 'dessous', 'chacune', 'moi', 's’', 'basee', 'juste', 'plouf', 'boum', 'quand', 'semblaient', 'treize', 'Bonjour', 'bah', 'desquels', 'faisant', 'es', 'permet', 'da', 'dès', 'touchant', 'hou', 'pour', 'plus', 'tous', 'uns', 'paf', 'chiche', 'qu’', 'hue', 'où', 'pff', 'remarquable', 'aucune', 'tardive', 'toutefois', 'particulièrement', 'ni', 'hep', 'ta', 'vive', 'nouveau', 'elle-même', 'directe', 'quelque', 'absolument', 'donc', 'possible', 'soi-même', 'ohé', 'nôtres', 'dring', 'cent', 'entre', 'eux-mêmes', 'ore', 'puis', 'avec', 'partant', 'uniformement', 'na', 'parseme', 'naturel', 'va', 'là', 'dans', 'vu', 'huit', 'neuf', 'tu', 'troisièmement', 'quelques', 'particulière', 'psitt', 'cinquantaine', 'suffit', 'ah', 'toute', 'deux', 'celles-là', 'leurs', 'restent', 'ils', 'etaient', 'vos', 'feront', 'quatre', 'different'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "\n",
    "#print(STOP_WORDS) # <- set of Spacy's default stop words\n",
    "\n",
    "STOP_WORDS.add(\"Bonjour\")\n",
    "print(STOP_WORDS) \n",
    "#for word in STOP_WORDS:\n",
    "#    lexeme = nlp.vocab[word]\n",
    "#    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bonjour', 'concernant', 'point', 'livraison', 'domaine', 'la', 'couronne', 'alba', 'la', 'romaine', '07400', 'enedis', '/', '30001970124818', 'je', \"n'\", 'factures', 'juillet', 'aout', 'mentionnées', 'fichiers', 'introuvables', 'pouvez', 'apporter', 'solution', 'problème', 'cdt', 'b.blachier']\n"
     ]
    }
   ],
   "source": [
    "# On récupère et on affiche les tokens QUE SI ce ne sont pas des stop words ou des caractères de ponctuation\n",
    "words = [w.text for w in doc_fr if not w.is_stop and w.pos_ != \"PUNCT\"]\n",
    "# Make all tokens lowercase\n",
    "doc = [w.lower() for w in words]\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-Of-Speech-Tagging (POS-Tagging)\n",
    "Le POS-Tagging consiste à associer un mot à sa classe morphosyntaxique (nom, verbe, adjectif,...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : Bonjour////// Tag : PROPN___////// Dep : ROOT///// Racine : Bonjour\n",
      "Word : ,////// Tag : PUNCT___////// Dep : punct///// Racine : ,\n",
      "Word : Concernant////// Tag : VERB__Tense=Pres|VerbForm=Part////// Dep : acl///// Racine : concerner\n",
      "Word : le////// Tag : DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art////// Dep : det///// Racine : le\n",
      "Word : point////// Tag : NOUN__Gender=Masc|Number=Sing////// Dep : obj///// Racine : point\n",
      "Word : de////// Tag : ADP___////// Dep : case///// Racine : de\n",
      "Word : livraison////// Tag : NOUN__Gender=Fem|Number=Sing////// Dep : nmod///// Racine : livraison\n",
      "Word : DOMAINE////// Tag : NOUN__Gender=Masc|Number=Sing////// Dep : acl///// Racine : domaine\n",
      "Word : LA////// Tag : DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art////// Dep : det///// Racine : le\n",
      "Word : COURONNE////// Tag : NOUN__Gender=Masc|Number=Sing////// Dep : obj///// Racine : couronne\n",
      "Word : ALBA////// Tag : X___////// Dep : ROOT///// Racine : ALBA\n",
      "Word : LA////// Tag : DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art////// Dep : det///// Racine : le\n",
      "Word : ROMAINE////// Tag : NOUN__Gender=Fem|Number=Sing////// Dep : ROOT///// Racine : romaine\n",
      "Word : 07400////// Tag : NUM__NumType=Card////// Dep : nummod///// Racine : 07400\n",
      "Word : ENEDIS////// Tag : NOUN__Gender=Fem|Number=Plur////// Dep : ROOT///// Racine : enedi\n",
      "Word : /////// Tag : ADP___////// Dep : case///// Racine : /\n",
      "Word : 30001970124818////// Tag : NUM__NumType=Card////// Dep : nummod///// Racine : 30001970124818\n",
      "Word : Je////// Tag : PRON__Number=Sing|Person=1////// Dep : nsubj///// Racine : il\n",
      "Word : n'////// Tag : ADV__Polarity=Neg////// Dep : advmod///// Racine : ne\n",
      "Word : ai////// Tag : VERB__Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin////// Dep : ROOT///// Racine : avoir\n",
      "Word : que////// Tag : SCONJ___////// Dep : mark///// Racine : que\n",
      "Word : les////// Tag : DET__Definite=Def|Number=Plur|PronType=Art////// Dep : det///// Racine : le\n",
      "Word : factures////// Tag : NOUN__Gender=Fem|Number=Plur////// Dep : nsubj:pass///// Racine : facture\n",
      "Word : de////// Tag : ADP___////// Dep : case///// Racine : de\n",
      "Word : juillet////// Tag : NOUN__Gender=Masc|Number=Sing////// Dep : nmod///// Racine : juillet\n",
      "Word : et////// Tag : CCONJ___////// Dep : cc///// Racine : et\n",
      "Word : aout////// Tag : ADV___////// Dep : conj///// Racine : aout\n",
      "Word : ,////// Tag : PUNCT___////// Dep : punct///// Racine : ,\n",
      "Word : les////// Tag : DET__Definite=Def|Number=Plur|PronType=Art////// Dep : det///// Racine : le\n",
      "Word : autres////// Tag : ADJ__Number=Plur////// Dep : nsubj:pass///// Racine : autre\n",
      "Word : sont////// Tag : AUX__Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin////// Dep : aux:pass///// Racine : être\n",
      "Word : mentionnées////// Tag : VERB__Gender=Fem|Number=Plur|Tense=Past|VerbForm=Part|Voice=Pass////// Dep : ccomp///// Racine : mentionner\n",
      "Word : fichiers////// Tag : ADJ__Gender=Masc|Number=Plur////// Dep : amod///// Racine : fichier\n",
      "Word : introuvables////// Tag : ADJ__Number=Plur////// Dep : amod///// Racine : introuvable\n",
      "Word : .////// Tag : PUNCT___////// Dep : punct///// Racine : .\n",
      "Word : Pouvez////// Tag : AUX__Mood=Ind|Number=Plur|Person=2|Tense=Pres|VerbForm=Fin////// Dep : aux///// Racine : pouvoir\n",
      "Word : apporter////// Tag : VERB__VerbForm=Inf////// Dep : ROOT///// Racine : apporter\n",
      "Word : une////// Tag : DET__Definite=Ind|Gender=Fem|Number=Sing|PronType=Art////// Dep : det///// Racine : un\n",
      "Word : solution////// Tag : NOUN__Gender=Fem|Number=Sing////// Dep : obj///// Racine : solution\n",
      "Word : à////// Tag : ADP___////// Dep : case///// Racine : à\n",
      "Word : ce////// Tag : DET__Gender=Masc|Number=Sing|PronType=Dem////// Dep : det///// Racine : ce\n",
      "Word : problème////// Tag : NOUN__Gender=Masc|Number=Sing////// Dep : nmod///// Racine : problème\n",
      "Word : .////// Tag : PUNCT___////// Dep : punct///// Racine : .\n",
      "Word : Cdt////// Tag : NOUN__Gender=Fem|Number=Sing////// Dep : ROOT///// Racine : cdt\n",
      "Word : .////// Tag : PUNCT___////// Dep : punct///// Racine : .\n",
      "Word : B.BLACHIER////// Tag : PROPN___////// Dep : ROOT///// Racine : B.BLACHIER\n"
     ]
    }
   ],
   "source": [
    "# On affiche chaque token et son tag pour la phrase française\n",
    "for token in doc_fr:\n",
    "    print('Word : {0}////// Tag : {1}////// Dep : {2}///// Racine : {3}' .format(token.text, token.tag_, token.dep_, token.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.fr.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
